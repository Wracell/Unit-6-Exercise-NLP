{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4fed96",
   "metadata": {},
   "source": [
    "**Exercise for Unit 6 - NLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c2ab28",
   "metadata": {},
   "source": [
    "**1. (70 points) Implement a Hidden Markov model in Python, using the training datasets given on the Assignment for Unit 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "754ac162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25e38e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Parse dataset\n",
    "data = [\n",
    "    \"The_DET cat_NOUN sleeps_VERB\",\n",
    "    \"A_DET dog_NOUN barks_VERB\",\n",
    "    \"The_DET dog_NOUN sleeps_VERB\",\n",
    "    \"My_DET dog_NOUN runs_VERB fast_ADV\",\n",
    "    \"A_DET cat_NOUN meows_VERB loudly_ADV\",\n",
    "    \"Your_DET cat_NOUN runs_VERB\",\n",
    "    \"The_DET bird_NOUN sings_VERB sweetly_ADV\",\n",
    "    \"A_DET bird_NOUN chirps_VERB\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ab0d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams = defaultdict(Counter)\n",
    "emissions = defaultdict(Counter)\n",
    "start_tags = Counter()\n",
    "tags = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7042bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract counts from dataset\n",
    "for sentence in data:\n",
    "    words_tags = sentence.split()\n",
    "    prev_tag = None\n",
    "    for i, wt in enumerate(words_tags):\n",
    "        word, tag = wt.rsplit(\"_\", 1)\n",
    "        emissions[tag][word.lower()] += 1  # convert to lowercase\n",
    "        tags.add(tag)\n",
    "        if i == 0:\n",
    "            start_tags[tag] += 1\n",
    "        if prev_tag is not None:\n",
    "            tag_bigrams[prev_tag][tag] += 1\n",
    "        prev_tag = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7294a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert counts to probabilities\n",
    "def normalize(counter):\n",
    "    total = sum(counter.values())\n",
    "    return {key: val / total for key, val in counter.items()}\n",
    "\n",
    "initial_probs = normalize(start_tags)\n",
    "transition_probs = {tag: normalize(counter) for tag, counter in tag_bigrams.items()}\n",
    "emission_probs = {tag: normalize(counter) for tag, counter in emissions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13c5f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Viterbi algorithm\n",
    "def viterbi(observation, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    path = {}\n",
    "\n",
    "    for y in states:\n",
    "        V[0][y] = math.log(start_p.get(y, 1e-10)) + math.log(emit_p.get(y, {}).get(observation[0], 1e-10))\n",
    "        path[y] = [y]\n",
    "\n",
    "    for t in range(1, len(observation)):\n",
    "        V.append({})\n",
    "        new_path = {}\n",
    "        for y in states:\n",
    "            (prob, state) = max(\n",
    "                (V[t-1][y0] + math.log(trans_p.get(y0, {}).get(y, 1e-10)) +\n",
    "                 math.log(emit_p.get(y, {}).get(observation[t], 1e-10)), y0)\n",
    "                for y0 in states\n",
    "            )\n",
    "            V[t][y] = prob\n",
    "            new_path[y] = path[state] + [y]\n",
    "        path = new_path\n",
    "\n",
    "    n = len(observation) - 1\n",
    "    (prob, state) = max((V[n][y], y) for y in states)\n",
    "    return path[state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73970a4d",
   "metadata": {},
   "source": [
    "**User Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ea717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: User input\n",
    "user_input = input(\"Enter a sentence: \").strip().lower()\n",
    "user_words = user_input.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c3fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DET', 'NOUN', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Predict tags\n",
    "predicted_tags = viterbi(user_words, tags, initial_probs, transition_probs, emission_probs)\n",
    "print (predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efb88bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted POS tags:\n",
      "the -> DET\n",
      "dog -> NOUN\n",
      "barks -> VERB\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Output\n",
    "print(\"\\nPredicted POS tags:\")\n",
    "for word, tag in zip(user_words, predicted_tags):\n",
    "    print(f\"{word} -> {tag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3f563",
   "metadata": {},
   "source": [
    "**2.\t(30 points) Implement Viterbi algorithm to determine the best PoS sequence on the following test sentences:**\n",
    "\n",
    "**a.\tThe can meows**\n",
    "\n",
    "**b.\tMy dog barks loudly**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76b631c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sentences\n",
    "test_sentences = {\n",
    "    \"a\": \"The can meows\",\n",
    "    \"b\": \"My dog barks loudly\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "333c396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence a: The can meows\n",
      "the -> DET\n",
      "can -> NOUN\n",
      "meows -> VERB\n",
      "\n",
      "Sentence b: My dog barks loudly\n",
      "my -> DET\n",
      "dog -> NOUN\n",
      "barks -> VERB\n",
      "loudly -> ADV\n"
     ]
    }
   ],
   "source": [
    "# Run Viterbi on each\n",
    "for label, sentence in test_sentences.items():\n",
    "    words = sentence.lower().split()\n",
    "    tags_seq = viterbi(words, tags, initial_probs, transition_probs, emission_probs)\n",
    "    print(f\"\\nSentence {label}: {sentence}\")\n",
    "    for word, tag in zip(words, tags_seq):\n",
    "        print(f\"{word} -> {tag}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
